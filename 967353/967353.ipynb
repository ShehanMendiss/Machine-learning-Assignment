{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"cfVBTVR95lR4"},"outputs":[],"source":["!pip install ultralytics"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"-wH3Zsl35ppi","executionInfo":{"status":"ok","timestamp":1713958336117,"user_tz":-330,"elapsed":4751,"user":{"displayName":"Fruit Cake","userId":"00373229138665021366"}}},"outputs":[],"source":["from ultralytics import YOLO"]},{"cell_type":"markdown","metadata":{"id":"D7JCx3_KE3LU"},"source":["Dataset URL = \"https://universe.roboflow.com/ds/w3ij6ZaPMb?key=2uavnSTR7t\"<br>\n","@misc{<br>\n","                            fruits-quality-qtdtf_dataset,<br>\n","                            title = { Fruits Quality Dataset },<br>\n","                            type = { Open Source Dataset },<br>\n","                            author = { Alex Day },<br>\n","                            howpublished = { \\url{ https://universe.roboflow.com/alex-day-qzfwa/fruits-quality-qtdtf } },<br>\n","                            url = { https://universe.roboflow.com/alex-day-qzfwa/fruits-quality-qtdtf },<br>\n","                            journal = { Roboflow Universe },<br>\n","                            publisher = { Roboflow },<br>\n","                            year = { 2023 },<br>\n","                            month = { oct },<br>\n","                            note = { visited on 2024-04-16 },<br>\n","                            }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UzWiIDw93nCR"},"outputs":[],"source":["!pip install roboflow\n","from roboflow import Roboflow\n","rf = Roboflow(api_key=\"Xh0IZO2YpH3j8mFq2SGG\")\n","project = rf.workspace(\"alex-day-qzfwa\").project(\"fruits-quality-qtdtf\")\n","version = project.version(1)\n","dataset = version.download(\"yolov8\")\n"]},{"cell_type":"code","source":["import os\n","\n","# Set the paths to your datasets\n","train_dir = '/content/Fruits-Quality-1/train'\n","test_dir = '/content/Fruits-Quality-1/test'\n","val_dir = '/content/Fruits-Quality-1/valid'\n","\n","# Function to count the number of files in a directory\n","def count_files(directory):\n","    count = 0\n","    for root, dirs, files in os.walk(directory):\n","        count += len(files)\n","    return count\n","\n","# Count the number of images in each dataset\n","train_count = count_files(train_dir)\n","test_count = count_files(test_dir)\n","val_count = count_files(val_dir)\n","\n","print(\"Number of images in training set:\", train_count)\n","print(\"Number of images in testing set:\", test_count)\n","print(\"Number of images in validation set:\", val_count)\n"],"metadata":{"id":"1ZnADamoCXPe"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_bi6Yifn5z2V"},"outputs":[],"source":["model = YOLO(\"yolov8n.pt\")"]},{"cell_type":"code","source":["# Train the model\n","results = model.train(data= '/content/Fruits-Quality-1/data.yaml', epochs=15, batch=8, imgsz=640)"],"metadata":{"id":"DQaKUc_D2p3r"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fvfDYRRC6Bql"},"outputs":[],"source":["# Load a model\n","model = YOLO('/content/runs/detect/train/weights/best.pt')  # Pretrained model\n","\n","# Run batched inference on a list of images\n","results = model(['Bad Apple.jpg'])  # return a list of Results objects\n","\n","# Process results list\n","for result in results:\n","    boxes = result.boxes  # Boxes object for bounding box outputs\n","    result.show()  # display to screen\n","    result.save(filename='Results.jpg')  # save to disk"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uabNrx7h_Pkk"},"outputs":[],"source":["# Load a model\n","model = YOLO('/content/runs/detect/train/weights/best.pt')  # pretrained YOLOv8n model\n","\n","# Run batched inference on a list of images\n","results = model(['Good Apple.jpg'])  # return a list of Results objects\n","\n","# Process results list\n","for result in results:\n","    boxes = result.boxes  # Boxes object for bounding box outputs\n","    result.show()  # display to screen\n","    result.save(filename='Result1.jpg')  # save to disk"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Smgl5-WoSR8P"},"outputs":[],"source":["# Load a model\n","model = YOLO('/content/runs/detect/train/weights/best.pt')  # pretrained YOLOv8n model\n","\n","# Run batched inference on a list of images\n","results = model(['Bad-pomegranate.jpg'])  # return a list of Results objects\n","\n","# Process results list\n","for result in results:\n","    boxes = result.boxes  # Boxes object for bounding box outputs\n","    result.show()  # display to screen\n","    result.save(filename='Result2.jpg')  # save to disk"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KmOrpdKrSpMf"},"outputs":[],"source":["# Load a model\n","model = YOLO('/content/runs/detect/train/weights/best.pt')  # pretrained YOLOv8n model\n","\n","# Run batched inference on a list of images\n","results = model(['Good pomegranate.jpg'])  # return a list of Results objects\n","\n","# Process results list\n","for result in results:\n","    boxes = result.boxes  # Boxes object for bounding box outputs\n","    result.show()  # display to screen\n","    result.save(filename='Result3.jpg')  # save to disk"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EcUsi6isUbgy"},"outputs":[],"source":["# Load a model\n","model = YOLO('/content/runs/detect/train/weights/best.pt')  # pretrained YOLOv8n model\n","\n","# Run batched inference on a list of images\n","results = model(['Banana Bad.jpg'])  # return a list of Results objects\n","\n","# Process results list\n","for result in results:\n","    boxes = result.boxes  # Boxes object for bounding box outputs\n","    result.show()  # display to screen\n","    result.save(filename='Result4.jpg')  # save to disk"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tunyabWqVo0n"},"outputs":[],"source":["# Load a model\n","model = YOLO('/content/runs/detect/train/weights/best.pt')  # pretrained YOLOv8n model\n","\n","# Run batched inference on a list of images\n","results = model(['Banana Good.jpg'])  # return a list of Results objects\n","\n","# Process results list\n","for result in results:\n","    boxes = result.boxes  # Boxes object for bounding box outputs\n","    result.show()  # display to screen\n","    result.save(filename='Result5.jpg')  # save to disk"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3TxepAm5fgQi"},"outputs":[],"source":["# Load a model\n","model = YOLO('/content/runs/detect/train/weights/best.pt')  # pretrained YOLOv8n model\n","\n","# Run batched inference on a list of images\n","results = model(['Guava Bad.jpg'])  # return a list of Results objects\n","\n","# Process results list\n","for result in results:\n","    boxes = result.boxes  # Boxes object for bounding box outputs\n","    result.show()  # display to screen\n","    result.save(filename='Result6.jpg')  # save to disk"]},{"cell_type":"code","source":["# Load a model\n","model = YOLO('/content/runs/detect/train/weights/best.pt')  # pretrained YOLOv8n model\n","\n","# Run batched inference on a list of images\n","results = model(['Good Guava.jpg'])  # return a list of Results objects\n","\n","# Process results list\n","for result in results:\n","    boxes = result.boxes  # Boxes object for bounding box outputs\n","    result.show()  # display to screen\n","    result.save(filename='Result7.jpg')  # save to disk"],"metadata":{"id":"8qKhmZMfyhb7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load a model\n","model = YOLO('/content/runs/detect/train/weights/best.pt')  # pretrained YOLOv8n model\n","\n","# Run batched inference on a list of images\n","results = model(['Lime Bad.jpg'])  # return a list of Results objects\n","\n","# Process results list\n","for result in results:\n","    boxes = result.boxes  # Boxes object for bounding box outputs\n","    result.show()  # display to screen\n","    result.save(filename='Result8.jpg')  # save to disk"],"metadata":{"id":"N9CaIdXkyhZL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load a model\n","model = YOLO('/content/runs/detect/train/weights/best.pt')  # pretrained YOLOv8n model\n","\n","# Run batched inference on a list of images\n","results = model(['Lime Good.jpg'])  # return a list of Results objects\n","\n","# Process results list\n","for result in results:\n","    boxes = result.boxes  # Boxes object for bounding box outputs\n","    result.show()  # display to screen\n","    result.save(filename='Result9.jpg')  # save to disk"],"metadata":{"id":"EQ8qQ8QfyhWD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load a model\n","model = YOLO('/content/runs/detect/train/weights/best.pt')  # pretrained YOLOv8n model\n","\n","# Run batched inference on a list of images\n","results = model(['Orange Bad.jpg'])  # return a list of Results objects\n","\n","# Process results list\n","for result in results:\n","    boxes = result.boxes  # Boxes object for bounding box outputs\n","    result.show()  # display to screen\n","    result.save(filename='Result10.jpg')  # save to disk"],"metadata":{"id":"TKWE5WwiyhOb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load a model\n","model = YOLO('/content/runs/detect/train/weights/best.pt')  # pretrained YOLOv8n model\n","\n","# Run batched inference on a list of images\n","results = model(['Orange Good.jpg'])  # return a list of Results objects\n","\n","# Process results list\n","for result in results:\n","    boxes = result.boxes  # Boxes object for bounding box outputs\n","    result.show()  # display to screen\n","    result.save(filename='Result11.jpg')  # save to disk"],"metadata":{"id":"4IqKaoJMyg8l"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rsfp5g0G6GFt"},"outputs":[],"source":["# Load a model\n","#model = YOLO('yolov8n.pt')  # load an official model\n","model = YOLO('/content/runs/detect/train/weights/best.pt')  # load a custom model\n","\n","# Validate the model\n","metrics = model.val()  # no arguments needed, dataset and settings remembered\n","metrics.box.map    # map50-95\n","metrics.box.map50  # map50\n","metrics.box.map75  # map75\n","metrics.box.maps   # a list contains map50-95 of each category"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}